Put your models in this folder and use in the chain
and uncomment this code: -

# if you want to run locally using Mistral model uncomment the following code: -  
#     llm = LlamaCpp(
#     model_path=r"Models\Your local Model",
#     temperature=0.5,
#      top_p=1, 
#      verbose=True,
#      n_ctx=4096 
# ) 